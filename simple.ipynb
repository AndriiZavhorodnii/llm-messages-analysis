{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "source: https://medium.com/@lucafiaschi/turning-customers-feedback-into-action-an-llm-blueprint-for-app-review-analysis-7f5d39d08f6e",
   "id": "bb0d60ce5d9cf630"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:56:54.339682Z",
     "start_time": "2025-06-21T11:56:53.512702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "from yaml_helper import YamlParser"
   ],
   "id": "af4dcc9f13883757",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T15:38:03.150098Z",
     "start_time": "2025-06-21T15:38:03.072594Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"data/headhway_review_rating.csv\")",
   "id": "e7c3af31c00d6a8a",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T15:38:34.707385Z",
     "start_time": "2025-06-21T15:38:34.673133Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[df.rating < 4]",
   "id": "5604f20be0cbffd2",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:56:54.951935Z",
     "start_time": "2025-06-21T11:56:54.924899Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[df.rating < 4].to_csv(\"data/headhway_review_rating_sample.csv\", index=False)",
   "id": "5a73ef3bdc3d55f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:56:55.270114Z",
     "start_time": "2025-06-21T11:56:55.266175Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.loc[df.rating < 4].reset_index(drop=True)",
   "id": "8846a64db6cd21d7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:05:57.423691Z",
     "start_time": "2025-06-21T13:05:57.373258Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"data/bad_df.csv\")",
   "id": "83a1a41f684e64a0",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:05:58.890332Z",
     "start_time": "2025-06-21T13:05:58.883861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "creds = YamlParser(\"creds/openai.yml\").read()\n",
    "OPENAI_API_KEY = creds[\"OPENAI_API_KEY\"]\n",
    "\n",
    "GEMINI_API_KEY = YamlParser(\"creds/gemini.yml\").read()[\"GEMINI_KEY\"]"
   ],
   "id": "48f3a211d0c29fdc",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:06:07.687613Z",
     "start_time": "2025-06-21T13:06:07.683371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    with open(\"prompts/message_sentiments_prompt.md\", 'r', encoding='utf-8') as file:\n",
    "        MARKDOWN_PROMPT = file.read()\n",
    "        # Now the 'markdown_content' variable holds the entire content of the file.\n",
    "        # You can now print it, process it, etc.\n",
    "        # For example:\n",
    "        # print(markdown_content)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file could not be found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(MARKDOWN_PROMPT)"
   ],
   "id": "e3d36adee33b3ad8",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:06:16.754395Z",
     "start_time": "2025-06-21T13:06:16.750690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retry_on_error(max_retries=5, sleep_time=5):\n",
    "    \"\"\"\n",
    "    Handy decorator to fight the crashes in the API\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator_retry(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            retries = 0\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    result = func(*args, **kwargs)\n",
    "                    return result\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    retries += 1\n",
    "                    time.sleep(sleep_time)\n",
    "            return None\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator_retry"
   ],
   "id": "f9a90f8d8b72ce5",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:08:58.561084Z",
     "start_time": "2025-06-21T11:08:58.557717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Setup Logging ---\n",
    "import logging\n",
    "\n",
    "date_string = datetime.datetime.now().date().isoformat()\n",
    "log_file_path = f\"logs/{date_string}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file_path),\n",
    "        # logging.StreamHandler() # Also print to console\n",
    "    ]\n",
    ")"
   ],
   "id": "30f6e035f9233e5",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:08:59.055200Z",
     "start_time": "2025-06-21T11:08:59.051809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai.api_key = OPENAI_API_KEY\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# client = openai.OpenAI(\n",
    "#     api_key=GEMINI_API_KEY,\n",
    "#     base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "# )\n",
    "@retry_on_error()\n",
    "def classify_topic(text, sleep_time=0.001, number=1):\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    prompt = MARKDOWN_PROMPT%(text)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.choices[0].message.content.strip())\n",
    "    result['content'] = text\n",
    "    time.sleep(sleep_time)\n",
    "    logging.info(f\"{number} - {result['content']}\")\n",
    "    return result"
   ],
   "id": "a998a995aa12bdda",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:06:32.969219Z",
     "start_time": "2025-06-21T13:06:31.418036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    res.append(classify_topic(text=row.get('content'), number=index))"
   ],
   "id": "e2e3865698efbe34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:30:14.033880Z",
     "start_time": "2025-06-21T11:08:59.960639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# res = Parallel(n_jobs=1, verbose=2)(delayed(classify_topic)(text=row.get('content'), number=index) for index, row in df.iterrows())\n",
    "\n",
    "# df_result = pd.DataFrame(res)"
   ],
   "id": "462146ef7c90600",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# res = Parallel(n_jobs=1, verbose=2)(delayed(print)(\"try:\\n\" + text) for text in df.content)",
   "id": "58b81f46f19474de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bcdb699f6ddd540d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
